# ðŸ§¬ FE-ACO: Federated Explainable Augmented Colony Optimization

[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-Apache_2.0-green.svg?style=for-the-badge)](https://opensource.org/licenses/Apache-2.0)

> **A GPU-Accelerated Graph Mining Engine for Privacy-Preserving Community Detection.**  
> *Developed as the Core Engine for the [SMART ADN] Startup.*

---

## ðŸš€ Overview

**FE-ACO(Federated Explainable Ant Colony Optimization)** is a novel algorithm designed to solve the **"Privacy vs. Accuracy"** trade-off in network analysis and bioinformatics. 

Traditional algorithms (like Louvain) require centralizing data, which violates privacy in healthcare and finance. FE-ACO utilizes a **Federated Swarm Architecture** reinforced by **Semantic Augmentation**, allowing it to outperform centralized state-of-the-art methods while maintaining **100% Data Sovereignty**.

It is specifically optimized for:
*   **Bioinformatics:** Protein-Protein Interaction (PPI) networks & Patient Stratification.
*   **Precision Medicine:** Detecting rare disease patterns (Leaf Nodes) in sparse data.
*   **Fraud Detection:** Identifying rings across siloed banking datasets.

---

## ðŸ† Benchmark Results (Cora Dataset)

FE-ACO was benchmarked against industry standards. It is the only algorithm that achieves high accuracy without seeing the global graph topology.

| Algorithm | Type | Privacy Level | NMI Score (Accuracy) | Status |
| :--- | :--- | :--- | :--- | :--- |
| **Louvain** | Topology (Classic) | 0% (Centralized) | 0.4300 | âŒ Beaten |
| **Node2Vec** | Deep Learning | 0% (Centralized) | 0.4700 | âŒ Beaten |
| **FE-ACO (Ours)** | **Federated Swarm** | **100% (Local GPU)** | **0.5173** | ðŸ‘‘ **Winner** |

> **Result:** FE-ACO outperforms the Louvain baseline by **+20.3%** and beats Deep Learning baselines, proving that semantic augmentation can compensate for topological fragmentation.

---

## ðŸ§  Key Innovations

### 1. Federated Semantic Augmentation
Instead of relying solely on graph edges (which are hidden in a federated setting), FE-ACO uses **Text/Sequence Embeddings** (e.g., ProtBERT, DNABERT) to create a "Semantic Gravity" field.
*   *Mechanism:* `Fused_Adj = Topology + (Weight * Semantic_Similarity)`
*   *Benefit:* Correctly classifies isolated nodes (Degree < 2) where standard algorithms fail.

### 2. Evolutionary Modularity Selection
Swarm algorithms are stochastic. To guarantee industrial stability, FE-ACO implements a **"Quality Gate"**:
*   It launches **30-100 parallel universes** on the GPU.
*   It calculates a **Hybrid Score** ($Score = Q \times (1+C)$) combining **Modularity (Structure)** and **Coherence (Semantics)**.
*   It autonomously selects the optimal model without requiring ground-truth labels.

### 3. Thermodynamic Stabilization
The engine uses **Simulated Annealing** with a quadratic inflation schedule:
*   **Phase 1 (Liquid):** Low inflation allows exploration of global structures.
*   **Phase 2 (Solid):** High inflation "freezes" the community boundaries.
*   **Result:** 100% convergence stability on core nodes.

### 4. Sparse Matrix Scalability
Designed for Big Data (100M+ Molecules):
*   Automatically switches to `torch.sparse.mm` for large graphs.
*   Memory efficient ($O(E)$ instead of $O(N^2)$).

---

## ðŸ¥ Integration in SMART ADN: Dynamic Virtual Screening

This engine is the technological backbone of the **SMART ADN** platform, specifically for the **Dynamic Virtual Screening** module.

By mapping biological entities to the graph structure, FE-ACO enables high-throughput drug discovery without centralizing sensitive proprietary data.

### How it works in Oncology:
1.  **The Graph:** Nodes represent **Target Proteins** (mutated in patients) and **Candidate Drugs** (from chemical libraries). Edges represent known biochemical interactions.
2.  **The Semantics (Augmentation):**
    *   **Proteins:** Encoded using **ProtBERT** / **DNABERT** embeddings (Sequence identity).
    *   **Drugs:** Encoded using **ChemBERTa** (Chemical structure identity).
3.  **The Discovery:** The Swarm naturally forms communities combining Proteins and Drugs.
    *   *Hypothesis:* If a Drug and a mutated Protein converge into the same **High-Confidence Community**, the drug is flagged as a potential therapeutic candidate (Drug Repurposing).

> **Impact:** This allows SMART ADN to perform **Federated Cohort Analysis** and **Personalized Therapy Ranking** across multiple hospitals, identifying treatments for rare variants where local data is insufficient.

## ðŸ›  Installation

```bash
git clone https://github.com/idrisrayanchakib-dev/fe-aco-engine.git
cd fe_aco
pip install -e .


âš¡ Quick Start
1. Running the Federated Simulation

import fe_aco

# 1. Load Data (Simulating 3 isolated hospitals)
adj, features, clients, labels = fe_aco.load_cora_federated()

# 2. Run the Engine (GPU Accelerated)
# The 'Quality Gate' ensures we only get a high-performance model
model = fe_aco.fit(
    adj_matrix=adj, 
    feature_matrix=features, 
    num_communities=7, 
    trials=50,          # Parallel Universes
    min_quality=0.82,   # Automatic Retry Threshold
    device='cuda'
)

# 3. Get Predictions
predictions = model.get_prediction()
print("Community Detection Complete.")

2. Generating an Explainability Report (Transparency)
Unlike "Black Box" GNNs, FE-ACO explains why a node belongs to a cluster.

# Analyze a specific node (e.g., Patient #1113)
report = fe_aco.generate_node_report(
    node_id=1113, 
    model=model, 
    adj_original=adj
)

print(report)

Output Example:

{
    "node_id": 1113,
    "cluster_id": 5,
    "confidence": "99.99%",
    "degree": 2,
    "analysis": "LEAF NODE (Follower - Strong Semantic Match)"
}


## ðŸ’¾ Data Format & Input Requirements

To use FE-ACO on your own biological or financial datasets, ensure your data is formatted as PyTorch Tensors.

| Input | Type | Shape | Description |
| :--- | :--- | :--- | :--- |
| **`adj_matrix`** | `torch.Tensor` | `(N, N)` | **Adjacency Matrix** (0 or 1). Represents interactions (Citations, PPI, Transactions). Can be `dense` or `sparse_coo`. |
| **`feature_matrix`** | `torch.Tensor` | `(N, D)` | **Semantic Embeddings**. Rows are nodes, Columns are features (e.g., Output from ProtBERT, DNABERT, or Word2Vec). |
| **`num_communities`** | `int` | Scalar | Expected number of clusters (e.g., 50 for cancer types). |

> **Note for Big Data:** For graphs with >20k nodes, pass `adj_matrix` as a **Sparse Tensor** (`torch.sparse_coo_tensor`) to automatically trigger the memory-efficient engine.


## âš™ï¸ Advanced Configuration (Hyperparameters)

You can fine-tune the engine behavior in `fe_aco.fit()`:

| Parameter | Default | Effect | Recommended Use |
| :--- | :--- | :--- | :--- |
| **`min_quality`** | `0.82` | **The Quality Gate.** Controls how strict the selection is. Higher = More retries, better accuracy. | Use `0.80` for speed, `0.88` for precision medicine. |
| **`aug_weight`** | `0.5` | **Semantic Pressure.** How much the text/DNA influences the graph topology. | Increase to `1.0` if graph connections are sparse/noisy. |
| **`top_k`** | `10` | **Context Window.** Number of semantic neighbors to consider. | Keep between `7` (Clean) and `15` (Exploratory). |
| **`trials`** | `30` | **Parallel Universes.** Number of independent swarms per attempt. | Use `10` for demos, `100` for final reports. |


## ðŸ–¥ï¸ Hardware Requirements

FE-ACO is built on **PyTorch** and automatically scales to available hardware.

*   **Minimum (Student/Demo):** NVIDIA GTX 1650 (4GB VRAM). Handles ~10k nodes.
*   **Recommended (Research):** NVIDIA RTX 3090 / 4090 (24GB VRAM). Handles ~100k nodes.
*   **Enterprise (SMART ADN Scale):** NVIDIA A100 / H100 (80GB VRAM). Handles **100M+ nodes** using the Sparse Engine.## ðŸ–¥ï¸ Hardware Requirements

FE-ACO is built on **PyTorch** and automatically scales to available hardware.

*   **Minimum (Student/Demo):** NVIDIA GTX 1650 (4GB VRAM). Handles ~10k nodes.
*   **Recommended (Research):** NVIDIA RTX 3090 / 4090 (24GB VRAM). Handles ~100k nodes.
*   **Enterprise (SMART ADN Scale):** NVIDIA A100 / H100 (80GB VRAM). Handles **100M+ nodes** using the Sparse Engine.


ðŸ“‚ Project Structure

fe_aco/
â”œâ”€â”€ __init__.py          # Main Orchestrator (Quality Gate Logic)
â”œâ”€â”€ engine.py            # Core GPU Engine (Sparse Matrix & Ant Colony)
â”œâ”€â”€ metrics.py           # Unsupervised Metrics (Modularity Q / Coherence C)
â”œâ”€â”€ explainability.py    # Transparency Module
â”œâ”€â”€ simulation.py        # Federated Data Loader
â””â”€â”€ visualization.py     # Plotting Tools for Reports


## ðŸ”® Roadmap

*   [x] **v1.0:** Core Engine (Sparse Matrix + GPU Support).
*   [x] **v1.1:** Evolutionary Quality Gate implementation.
*   [ ] **v2.0:** Integration with **ClinVar** API for real-time variant annotation.
*   [ ] **v2.1:** Multi-GPU sharding for datasets > 1 Billion nodes.
*   [ ] **v3.0:** Clinical Dashboard integration (FHIR Standard).


ðŸ“œ Citation & License
This project is part of the SMART ADN initiative for Precision Medicine.
Copyright Â© 2025. All rights reserved.
Author: Idris Rayan Chakib
