import torch
import fe_aco
import time
from sklearn.metrics import normalized_mutual_info_score as nmi_score

# 1. VÃ©rification du MatÃ©riel
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"ğŸ–¥ï¸  MatÃ©riel dÃ©tectÃ© : {device.upper()}")
if device == 'cuda':
    print(f"ğŸš€ Carte Graphique : {torch.cuda.get_device_name(0)}")

print("\n" + "="*50)
print("  DÃ‰MARRAGE DU PROTOCOLE SMART ADN (FE-ACO)")
print("="*50 + "\n")

# 2. Chargement des donnÃ©es
print("ğŸ“¥ Chargement des donnÃ©es Cora (Simulation FÃ©dÃ©rÃ©e)...")
try:
    adj, features, clients, labels = fe_aco.load_cora_federated(device=device)
    print("âœ… DonnÃ©es chargÃ©es sur le GPU.")
except ImportError as e:
    print(f"âŒ Erreur : {e}")
    exit()

# 3. Lancement du Moteur (100 TRIALS)
# On passe Ã  100 pour maximiser la chance d'avoir le record (0.5084)
start_time = time.time()

print("ğŸš€ Lancement de l'entraÃ®nement (100 Univers ParallÃ¨les)...")
model = fe_aco.fit(
    adj_matrix=adj, 
    feature_matrix=features, 
    num_communities=7, 
    trials=50,          # <--- ICI : On passe Ã  100
    device=device,
    clients=clients,
    min_quality=0.82
)

duration = time.time() - start_time
print(f"\nâ±ï¸  Temps de calcul : {duration:.2f} secondes")

# --- LE CALCUL DU NMI (Validation Externe) ---
# On rÃ©cupÃ¨re les prÃ©dictions du meilleur modÃ¨le
preds = model.get_prediction().cpu().numpy()
truth = labels.cpu().numpy()

# On calcule le score
final_nmi = nmi_score(truth, preds)

print("\n" + "-"*40)
print(f"ğŸ† RÃ‰SULTAT FINAL (40 Essais)")
print(f"ModularitÃ© (Q) : {fe_aco.metrics.calculate_modularity(adj, model.get_prediction(), 7):.4f}")
print(f"NMI Score      : {final_nmi:.4f}")  # <--- C'est ici qu'on voit si tu as battu Louvain
print("-" * 40)

# 4. Transparence
node_id = 1113
print(f"\nğŸ” Analyse du Patient #{node_id}...")
report = fe_aco.generate_node_report(node_id, model, adj, labels)
print("-" * 30)
print(f"Diagnostic : {report['analysis']}")
print(f"Confiance  : {report['confidence']}")
print(f"Vrai Label : {report['true_label']} | PrÃ©dit : {report['cluster_id']}")
print("-" * 30)

# 5. GÃ©nÃ©ration des Preuves
print("\nğŸ“Š GÃ©nÃ©ration du benchmark...")
# On passe le vrai NMI calculÃ© pour que le graphe soit prÃ©cis
from fe_aco.visualization import plot_benchmark_comparison
plot_benchmark_comparison(final_nmi, save_path="smart_adn_benchmark_100.png")

print("\nâœ… TEST TERMINÃ‰. VÃ©rifie 'smart_adn_benchmark_100.png'.")